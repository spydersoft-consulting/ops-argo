alloy:
  alloy:
    configMap:
      content: |
        
        remote.kubernetes.secret "vault_app_role_secret" {
          namespace = "cluster-tools"
          name = "k8-app-role-secret"
        }

        remote.vault "targets" {
          server = "https://hcvault.mattgerega.net"
          path = "secrets-k8/monitoring/targets/internal"

          auth.approle {
            role_id = "13f4cd25-b02f-f705-c92d-ef6bfeff1344"
            secret = remote.kubernetes.secret.vault_app_role_secret.data["secret-id"]
          }
        }

        remote.vault "minio" {
          server = "https://hcvault.mattgerega.net"
          path = "secrets-k8/monitoring/minio"

          auth.approle {
            role_id = "13f4cd25-b02f-f705-c92d-ef6bfeff1344"
            secret = remote.kubernetes.secret.vault_app_role_secret.data["secret-id"]
          }
        }

        remote.vault "vault" {
          server = "https://hcvault.mattgerega.net"
          path = "secrets-k8/monitoring/vault"

          auth.approle {
            role_id = "13f4cd25-b02f-f705-c92d-ef6bfeff1344"
            secret = remote.kubernetes.secret.vault_app_role_secret.data["secret-id"]
          }
        }

        remote.vault "garage" {
          server = "https://hcvault.mattgerega.net"
          path = "secrets-k8/monitoring/garage/metrics"

          auth.approle {
            role_id = "13f4cd25-b02f-f705-c92d-ef6bfeff1344"
            secret = remote.kubernetes.secret.vault_app_role_secret.data["secret-id"]
          }
        }

        prometheus.remote_write "default" {
          endpoint {
            url = "https://mimir.mattgerega.net/api/v1/push"
            headers = {
              "X-Scope-OrgID" = "internal",
            }
          }
          external_labels = {
            cluster = "internal",
            custom_source = "grafana-alloy",
          }
        }

        prometheus.scrape "minio_job" {
          targets = [{
            __address__ = convert.nonsensitive(remote.vault.targets.data["minio-target"]),
          }]
          forward_to   = [prometheus.remote_write.default.receiver]
          job_name     = "minio-job"
          metrics_path = "/minio/v2/metrics/cluster"

          authorization {
            type        = "Bearer"
            credentials = remote.vault.minio.data.authtoken
          }
        }

        prometheus.scrape "vault_job" {
          targets = [{
            __address__ = convert.nonsensitive(remote.vault.targets.data["vault-target"]),
          }]
          forward_to = [prometheus.remote_write.default.receiver]
          job_name   = "vault-job"
          params     = {
            format = ["prometheus"],
          }
          metrics_path = "/v1/sys/metrics"
          scheme       = "https"

          authorization {
            type        = "Bearer"
            credentials = remote.vault.vault.data["metric-token"]
          }
        }

        prometheus.scrape "garage_job" {
          targets = [{
            __address__ = convert.nonsensitive(remote.vault.targets.data["garage-target"]),
          }]
          forward_to   = [prometheus.remote_write.default.receiver]
          job_name     = "garage-job"
          metrics_path = "/metrics"
          scheme       = "http"

          authorization {
            type        = "Bearer"
            credentials = remote.vault.garage.data["metrics-token"]
          }
        }

        prometheus.scrape "unifi_poller_job" {
          targets = [{
            __address__ = "unifi-poller.monitoring.svc.cluster.local:9130",
          }]
          forward_to   = [prometheus.remote_write.default.receiver]
          job_name     = "unifi-poller-job"
          metrics_path = "/metrics"
          scheme       = "http"
        }

        prometheus.scrape "linkerd_gateway_job" {
          targets = [{
            __address__ = "linkerd-gateway.linkerd-multicluster.svc.cluster.local:4191",
          }]
          forward_to   = [prometheus.remote_write.default.receiver]
          job_name     = "linkerd-multicluster-gateway-job"
          metrics_path = "/metrics"
          scheme       = "http"
        }


        loki.write "default" {
          endpoint {
            url = "https://loki.mattgerega.net/loki/api/v1/push"
            tenant_id = "internal"
          }
          external_labels = {
            cluster = "internal",
            custom_source = "grafana-alloy",
          }
        }

        otelcol.processor.memory_limiter "default" {
          check_interval = "1s"
          limit          = "1GiB"

          output {
            metrics = [otelcol.processor.batch.default.input]
            logs    = [otelcol.processor.batch.default.input]
            traces  = [otelcol.processor.batch.default.input]
          }
        }

        otelcol.processor.batch "default" {
          output {
            metrics = [otelcol.exporter.prometheus.default.input]
            logs    = [otelcol.exporter.loki.default.input]
            traces  = [otelcol.exporter.otlp.default.input]
          }
        }
        otelcol.receiver.otlp "example" {
          grpc {
            endpoint = "0.0.0.0:4317"
          }

          http {
            endpoint = "0.0.0.0:4318"
          }

          output {
            metrics = [otelcol.processor.batch.default.input]
            logs    = [otelcol.processor.batch.default.input]
            traces  = [otelcol.processor.batch.default.input]
          }
        }

        otelcol.exporter.loki "default" {
          forward_to = [loki.write.default.receiver]
        }

        otelcol.exporter.prometheus "default" {
          forward_to = [prometheus.remote_write.default.receiver]
        }

        otelcol.exporter.otlp "default" {
          client {
            endpoint = "tfx-internal.gerega.net:32326"
            headers = {
              "X-Scope-OrgID" = "internal",
            }
            tls {
              insecure = true
            }
          }
        }